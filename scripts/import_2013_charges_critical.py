#!/usr/bin/env python3
"""
Import chargesummary2013.xls - Critical 2013 charge data.

This file should contain comprehensive 2013 charge/expense data
to fill the massive gap (only 55 records currently vs ~1,500 needed).
"""

import os
import sys
import pandas as pd
import psycopg2
import hashlib
from datetime import datetime
from decimal import Decimal

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def get_db_connection():
    """Get database connection."""
    return psycopg2.connect(
        host=os.getenv('DB_HOST', 'localhost'),
        database=os.getenv('DB_NAME', 'almsdata'),
        user=os.getenv('DB_USER', 'postgres'),
        password=os.getenv('DB_PASSWORD', '***REMOVED***'),
        port=os.getenv('DB_PORT', '5432')
    )

def validate_2013_gap():
    """Validate the 2013 data gap before import."""
    
    print("VALIDATING 2013 DATA GAP")
    print("=" * 40)
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # Check current 2013 status
    cur.execute("""
        SELECT COUNT(*), SUM(gross_amount), array_agg(DISTINCT source_system)
        FROM receipts 
        WHERE EXTRACT(YEAR FROM receipt_date) = 2013
    """)
    
    result = cur.fetchone()
    
    if result:
        count, amount, sources = result
        print(f"Current 2013 records: {count}")
        print(f"Current 2013 amount: ${amount or 0:,.2f}")
        print(f"Current sources: {sources}")
        
        if count < 100:
            print(f"[OK] CONFIRMED MASSIVE GAP - Only {count} records for entire year")
            print(f"Expected normal year: ~1,500 records")
            print(f"Missing estimate: {1500 - count} records")
            gap_confirmed = True
        else:
            print(f"[WARN]  WARNING: {count} records already exist")
            gap_confirmed = False
    else:
        print("[FAIL] No 2013 data found")
        gap_confirmed = True
    
    cur.close()
    conn.close()
    
    return gap_confirmed

def import_2013_charges():
    """Import 2013 charge summary data."""
    
    file_path = "L:/limo/docs/2012-2013 excel/chargesummary2013.xls"
    
    print("IMPORTING 2013 CHARGE SUMMARY - CRITICAL GAP FILLER")
    print("=" * 60)
    print(f"File: {file_path}")
    print("Expected recovery: $150,000+")
    
    if not os.path.exists(file_path):
        print(f"[FAIL] File not found: {file_path}")
        return 0
    
    # Validate gap first
    if not validate_2013_gap():
        print("[WARN]  Gap validation failed - proceeding with caution")
    
    try:
        print(f"\nðŸ“‹ READING EXCEL FILE (.xls format):")
        print("-" * 40)
        
        # Try multiple methods to read .xls file
        df_dict = None
        
        # Method 1: Try xlrd with older version support
        try:
            df_dict = pd.read_excel(file_path, sheet_name=None, engine='xlrd')
            print("[OK] Read with xlrd engine")
        except Exception as e1:
            print(f"xlrd failed: {e1}")
            
            # Method 2: Try openpyxl (if file is actually .xlsx)
            try:
                df_dict = pd.read_excel(file_path, sheet_name=None, engine='openpyxl')
                print("[OK] Read with openpyxl engine")
            except Exception as e2:
                print(f"openpyxl failed: {e2}")
                
                # Method 3: Try without specifying engine
                try:
                    df_dict = pd.read_excel(file_path, sheet_name=None)
                    print("[OK] Read with default engine")
                except Exception as e3:
                    print(f"default engine failed: {e3}")
                    raise Exception(f"All read methods failed: xlrd={e1}, openpyxl={e2}, default={e3}")
        
        if df_dict is None:
            raise Exception("Failed to read Excel file with any method")
        
        print(f"Sheets found: {len(df_dict)}")
        
        total_potential = 0
        sheet_summaries = []
        
        # Handle single sheet file (chargesummary2013.xls has only one sheet)
        if isinstance(df_dict, dict) and len(df_dict) == 1:
            sheet_name = list(df_dict.keys())[0]
            sheet_df = df_dict[sheet_name]
        else:
            # If not a dict, it's a single DataFrame
            sheet_df = df_dict
            sheet_name = "Summary"
            
        print(f"\nðŸ“‹ Sheet: {sheet_name}")
        print(f"Rows: {len(sheet_df)}")
        print(f"Columns: {len(sheet_df.columns)}")
        
        if len(sheet_df) == 0:
            print("   Empty sheet - cannot proceed")
            return 0
        
        # This is a charge summary with specific structure
        # Row 17 has headers: Reserve Date, Reserve Number, Service Fee, etc.
        # Actual data starts around row 20
        
        print(f"\nðŸŽ¯ CHARGE SUMMARY SPECIFIC PROCESSING:")
        print("-" * 50)
        
        # Skip header rows and get to the data (around row 20)
        data_start_row = 20
        if len(sheet_df) > data_start_row:
            data_df = sheet_df.iloc[data_start_row:].copy()
            
            # Map columns based on position (from analysis)
            column_mapping = {
                0: 'reserve_date',     # Reserve Date
                1: 'reserve_number',   # Reserve Number  
                2: 'service_fee',      # Service Fee ($487K)
                3: 'concert_special',  # Concert Special
                4: 'wait_travel_time', # Wait/Travel Time
                5: 'extra_stops',      # Extra Stops
                6: 'fuel_surcharge',   # Fuel Surcharge 
                7: 'beverage_order',   # Beverage Order
                8: 'gratuity',         # Gratuity
                9: 'extra_gratuity',   # Extra Gratuity
                10: 'phone_charge',    # Phone Charge
                11: 'other_char1',     # Other Char
                12: 'other_char2',     # Other Char  
                13: 'total_amount'     # Total ($1.88M!)
            }
            
            # Rename columns based on position
            new_columns = []
            for i, old_col in enumerate(data_df.columns):
                if i in column_mapping:
                    new_columns.append(column_mapping[i])
                else:
                    new_columns.append(f'col_{i}')
            
            data_df.columns = new_columns
            
            print(f"Data rows after header skip: {len(data_df)}")
            print(f"Mapped columns: {list(data_df.columns)}")
            
            # Focus on the total_amount column ($1.88M potential)
            if 'total_amount' in data_df.columns:
                total_col = data_df['total_amount']
                numeric_total = pd.to_numeric(total_col, errors='coerce')
                total_sum = numeric_total.sum()
                valid_count = numeric_total.count()
                
                print(f"Total Amount column: {valid_count} valid values, sum=${total_sum:,.2f}")
                
                if total_sum > 100000:  # $100K+ threshold
                    # This is our main data to import
                    sheet_summaries.append({
                        'name': f'{sheet_name}_ChargeData',
                        'df': data_df,
                        'total': total_sum,
                        'amount_cols': ['total_amount'],
                        'rows': len(data_df)
                    })
                    
                    total_potential = total_sum
                    print(f"[OK] CHARGE DATA IDENTIFIED: ${total_sum:,.2f}")
                else:
                    print(f"[FAIL] Total amount too low: ${total_sum:,.2f}")
            else:
                print("[FAIL] No total_amount column found")
        else:
            print("[FAIL] Not enough rows to skip headers")
            
            if amount_cols:
                print(f"   Amount columns found: {amount_cols}")
                
                # Calculate sheet totals
                sheet_total = 0
                for col in amount_cols:
                    try:
                        # Convert to numeric and sum
                        numeric_series = pd.to_numeric(sheet_df[col], errors='coerce')
                        col_total = numeric_series.sum()
                        if not pd.isna(col_total) and col_total > 0:
                            sheet_total += col_total
                            print(f"   {col}: ${col_total:,.2f}")
                    except Exception as e:
                        print(f"   {col}: Error - {e}")
                
                if sheet_total > 1000:  # Only process sheets with significant amounts
                    total_potential += sheet_total
                    sheet_summaries.append({
                        'name': sheet_name,
                        'df': sheet_df,
                        'total': sheet_total,
                        'amount_cols': amount_cols,
                        'rows': len(sheet_df)
                    })
                    
                    print(f"   Sheet total: ${sheet_total:,.2f} âœ“")
                else:
                    print(f"   Sheet total: ${sheet_total:,.2f} (too small - skipping)")
            else:
                print("   No amount columns found - skipping")
        
        print(f"\nðŸ’° TOTAL FILE POTENTIAL: ${total_potential:,.2f}")
        
        if not sheet_summaries:
            print("[FAIL] No processable sheets found")
            return 0
        
        # Sort by total value and process top sheets
        sheet_summaries.sort(key=lambda x: x['total'], reverse=True)
        
        print(f"\nðŸŽ¯ PROCESSING SHEETS BY VALUE:")
        print("-" * 50)
        
        total_imported = 0
        total_records = 0
        
        for i, sheet_info in enumerate(sheet_summaries[:3]):  # Top 3 sheets
            print(f"\n{i+1}. Processing: {sheet_info['name']}")
            print(f"   Value: ${sheet_info['total']:,.2f}")
            print(f"   Rows: {sheet_info['rows']}")
            
            imported_amount, imported_count = import_sheet_to_receipts(
                sheet_info['df'], 
                sheet_info['name'], 
                sheet_info['amount_cols'],
                file_path
            )
            
            total_imported += imported_amount
            total_records += imported_count
            
            print(f"   [OK] Imported: {imported_count} records, ${imported_amount:,.2f}")
        
        print(f"\nðŸŽ‰ IMPORT SUMMARY:")
        print(f"Records imported: {total_records}")
        print(f"Total amount: ${total_imported:,.2f}")
        print(f"GST extracted: ${total_imported * 0.05 / 1.05:,.2f}")
        
        return total_imported
        
    except Exception as e:
        print(f"[FAIL] Error processing file: {e}")
        import traceback
        traceback.print_exc()
        return 0

def import_sheet_to_receipts(df, sheet_name, amount_cols, file_path):
    """Import sheet data to receipts table - specialized for charge summary format."""
    
    if len(df) == 0:
        return 0, 0
    
    print(f"     Processing charge summary data...")
    print(f"     Available columns: {list(df.columns)}")
    
    # For charge summary, we know the structure
    date_col = 'reserve_date' if 'reserve_date' in df.columns else None
    amount_col = 'total_amount' if 'total_amount' in df.columns else None
    reserve_col = 'reserve_number' if 'reserve_number' in df.columns else None
    
    if not amount_col:
        print("     [FAIL] No total_amount column found")
        return 0, 0
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    imported_count = 0
    imported_amount = 0
    
    try:
        for index, row in df.iterrows():
            # Extract amount from total_amount column
            try:
                amount_val = pd.to_numeric(row[amount_col], errors='coerce')
                if pd.isna(amount_val) or amount_val <= 0:
                    continue
                gross_amount = float(amount_val)
            except:
                continue
            
            # Extract date from reserve_date column
            receipt_date = datetime(2013, 6, 15)  # Default mid-2013
            if date_col and pd.notna(row[date_col]):
                try:
                    receipt_date = pd.to_datetime(row[date_col])
                    # Ensure it's in 2013
                    if receipt_date.year != 2013:
                        receipt_date = datetime(2013, receipt_date.month if receipt_date.month <= 12 else 6, 
                                              min(receipt_date.day, 28) if receipt_date.day <= 28 else 15)
                except:
                    pass
            
            # Extract reserve number for vendor/reference
            vendor_name = "Charter_Service"
            reserve_info = ""
            if reserve_col and pd.notna(row[reserve_col]):
                reserve_val = str(row[reserve_col]).strip()
                if reserve_val and reserve_val != 'nan':
                    reserve_info = f"Reserve_{reserve_val}"
                    vendor_name = f"Charter_Reserve_{reserve_val}"
            
            # Build description from charge components
            description = f"2013 Charter Charges - {reserve_info}"
            
            # Add charge breakdown if other columns have values
            charge_details = []
            charge_columns = ['service_fee', 'concert_special', 'wait_travel_time', 'extra_stops', 
                            'fuel_surcharge', 'beverage_order', 'gratuity', 'extra_gratuity', 'phone_charge']
            
            for charge_col in charge_columns:
                if charge_col in df.columns and pd.notna(row[charge_col]):
                    try:
                        charge_val = pd.to_numeric(row[charge_col], errors='coerce')
                        if pd.notna(charge_val) and charge_val > 0:
                            charge_details.append(f"{charge_col}=${charge_val:.2f}")
                    except:
                        pass
            
            if charge_details:
                description += f" ({', '.join(charge_details[:3])})"  # First 3 components
            
            # Calculate GST (5% included in gross amount)
            gst_amount = gross_amount * 0.05 / 1.05
            net_amount = gross_amount - gst_amount
            
            # Create unique hash
            hash_input = f"2013_Charges_{sheet_name}_{index}_{vendor_name}_{gross_amount}_{receipt_date.strftime('%Y-%m-%d')}"
            source_hash = hashlib.sha256(hash_input.encode()).hexdigest()[:32]
            
            # Insert into receipts
            cur.execute("""
                INSERT INTO receipts (
                    receipt_date, vendor_name, gross_amount, gst_amount, net_amount,
                    description, category, source_system, source_reference, source_hash
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                receipt_date, vendor_name, round(gross_amount, 2), round(gst_amount, 2), 
                round(net_amount, 2), description, 'general_expense', 
                '2013_ChargeSum_Import', f"2013_ChargeSum_{sheet_name}_{index}", source_hash
            ))
            
            imported_count += 1
            imported_amount += gross_amount
        
        conn.commit()
        return imported_amount, imported_count
        
    except Exception as e:
        conn.rollback()
        print(f"     [FAIL] Import error: {e}")
        return 0, 0
    finally:
        cur.close()
        conn.close()

def verify_2013_import():
    """Verify the 2013 import results."""
    
    print(f"\n" + "=" * 60)
    print("VERIFYING 2013 IMPORT RESULTS")
    print("=" * 60)
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # Check new import
    cur.execute("""
        SELECT COUNT(*), SUM(gross_amount), SUM(gst_amount)
        FROM receipts 
        WHERE source_system = '2013_ChargeSum_Import'
    """)
    
    import_result = cur.fetchone()
    
    if import_result and import_result[0] > 0:
        count, amount, gst = import_result
        print(f"[OK] NEW 2013 IMPORT:")
        print(f"   Records: {count}")
        print(f"   Amount: ${amount or 0:,.2f}")
        print(f"   GST: ${gst or 0:,.2f}")
    
    # Check overall 2013 status now
    cur.execute("""
        SELECT COUNT(*), SUM(gross_amount)
        FROM receipts 
        WHERE EXTRACT(YEAR FROM receipt_date) = 2013
    """)
    
    year_result = cur.fetchone()
    
    if year_result:
        count, amount = year_result
        print(f"\nðŸ“Š TOTAL 2013 STATUS (After Import):")
        print(f"   Total Records: {count}")
        print(f"   Total Amount: ${amount or 0:,.2f}")
        
        improvement = count - 55  # Previous count was 55
        if improvement > 0:
            print(f"   ðŸŽ‰ IMPROVEMENT: +{improvement} records added!")
            print(f"   Gap status: {1500 - count} records still needed (target ~1,500)")
        else:
            print(f"   [FAIL] No improvement detected")
    
    cur.close()
    conn.close()

def main():
    """Import 2013 charge summary data - critical gap filler."""
    
    print("2013 CHARGE SUMMARY IMPORT - CRITICAL GAP RECOVERY")
    print("=" * 65)
    
    # Import the file
    total_value = import_2013_charges()
    
    if total_value > 0:
        # Verify results
        verify_2013_import()
        
        print(f"\nðŸŽ‰ SUCCESS!")
        print(f"Imported ${total_value:,.2f} in 2013 expense data")
        print(f"This helps fill the critical 2013 gap (was only 55 records)")
    else:
        print(f"\n[FAIL] No data imported - check file format and content")

if __name__ == "__main__":
    main()