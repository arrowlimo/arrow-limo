"""
Import receipts from the color-coded Excel workbook back into the database.

Features
- Reads the 'Receipts' sheet from the reconciliation Excel
- Updates existing receipts by receipt_id, inserts new when receipt_id missing
- Duplicate prevention via WHERE NOT EXISTS and deterministic source_hash
- Dry-run by default; use --write to apply changes
- Optional backup CSV export of changed rows with --backup

Usage
    python -X utf8 l:\limo\scripts\import_receipts_from_excel.py --file l:\limo\reports\receipts_reconciliation_YYYYMMDD_HHMMSS.xlsx --dry-run
    python -X utf8 l:\limo\scripts\import_receipts_from_excel.py --file l:\limo\reports\receipts_reconciliation_YYYYMMDD_HHMMSS.xlsx --write --backup
"""
import argparse
import os
import sys
import hashlib
import pandas as pd
import psycopg2
from datetime import datetime

DB_HOST = os.environ.get("DB_HOST", "localhost")
DB_NAME = os.environ.get("DB_NAME", "almsdata")
DB_USER = os.environ.get("DB_USER", "postgres")
DB_PASSWORD = os.environ.get("DB_PASSWORD", os.environ.get("DB_PASSWORD"))

KEY_COLUMNS = [
    'receipt_date','vendor_name','gross_amount','card_number','vehicle_number','description'
]

UPDATE_COLUMNS = [
    'vendor_name','canonical_vendor','description','gross_amount','gst_amount','net_amount',
    'expense_account','payment_method','canonical_pay_method','card_type','card_number',
    'vehicle_id','vehicle_number','fuel_amount','fuel','category','classification',
    'sub_classification','is_personal_purchase','business_personal','is_split_receipt',
    'parent_receipt_id','is_driver_reimbursement','reimbursed_via','reimbursement_date',
    'cash_box_transaction_id','comment','deductible_status','owner_personal_amount',
    'amount_usd','fx_rate','gl_account_code','gl_account_name','gl_subcategory'
]

INSERT_COLUMNS = ['receipt_date','currency','source_system','source_reference','source_file','validation_status'] + UPDATE_COLUMNS


def compute_source_hash(row):
    parts = []
    for k in KEY_COLUMNS:
        v = row.get(k)
        parts.append(str(v) if pd.notna(v) else '')
    base = '|'.join(parts)
    return hashlib.sha256(base.encode('utf-8')).hexdigest()


def connect_db():
    return psycopg2.connect(host=DB_HOST, database=DB_NAME, user=DB_USER, password=DB_PASSWORD)


def upsert_receipt(cur, row, write=False):
    receipt_id = row.get('receipt_id')
    if pd.notna(receipt_id):
        # UPDATE
        set_pairs = []
        values = []
        for col in UPDATE_COLUMNS:
            if col in row:
                set_pairs.append(f"{col} = %s")
                values.append(row.get(col))
        if not set_pairs:
            return 'skip', None
        values.append(receipt_id)
        sql = f"UPDATE receipts SET {', '.join(set_pairs)} WHERE receipt_id = %s"
        if write:
            cur.execute(sql, values)
        return 'update', sql
    else:
        # INSERT (id generated by sequence)
        cols = []
        placeholders = []
        values = []
        for col in INSERT_COLUMNS:
            if col in row:
                cols.append(col)
                placeholders.append('%s')
                values.append(row.get(col))
        # Compute source_hash for dedup
        src_hash = compute_source_hash(row)
        cols.append('source_hash')
        placeholders.append('%s')
        values.append(src_hash)
        # Duplicate prevention: same keys OR source_hash
        where_not_exists = (
            "WHERE NOT EXISTS (\n"
            "  SELECT 1 FROM receipts r\n"
            "  WHERE r.source_hash = %s\n"
            ")"
        )
        values.insert(0, src_hash)
        sql = (
            f"INSERT INTO receipts ({', '.join(cols)})\n"
            f"SELECT {', '.join(placeholders)}\n"
            f"{where_not_exists}"
        )
        if write:
            cur.execute(sql, values)
        return 'insert', sql


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--file', required=True, help='Path to Excel reconciliation file')
    parser.add_argument('--write', action='store_true', help='Apply changes')
    parser.add_argument('--dry-run', action='store_true', help='Preview only (default)')
    parser.add_argument('--backup', action='store_true', help='Export backup CSV of changed rows')
    args = parser.parse_args()

    if not args.write:
        args.dry_run = True

    print(f"Reading Excel: {args.file}")
    df = pd.read_excel(args.file, sheet_name='Receipts')

    conn = connect_db()
    cur = conn.cursor()

    changed_rows = []
    inserts = updates = skips = 0

    for _, row in df.iterrows():
        data = {k: (row[k] if k in df.columns else None) for k in set(df.columns)}
        action, sql = upsert_receipt(cur, data, write=args.write)
        if action == 'insert':
            inserts += 1
            changed_rows.append(data)
        elif action == 'update':
            updates += 1
            changed_rows.append(data)
        else:
            skips += 1

    if args.write:
        conn.commit()
        print(f"âœ… Committed: {inserts} inserts, {updates} updates, {skips} skips")
    else:
        conn.rollback()
        print(f"ðŸ”Ž Dry-run: {inserts} potential inserts, {updates} potential updates, {skips} skips")

    if args.backup and changed_rows:
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        out = f"l:\\limo\\reports\\receipts_import_backup_{ts}.csv"
        pd.DataFrame(changed_rows).to_csv(out, index=False)
        print(f"ðŸ“¦ Backup written: {out}")

    cur.close()
    conn.close()

if __name__ == '__main__':
    main()
#!/usr/bin/env python3
"""
Import receipts from the Excel file 'reports/new receipts fileoct.xlsx' into the normalized receipts table.

Safety first:
- Default is dry-run: produce a preview CSV at reports/receipts_import_preview.csv and print a summary.
- Use --commit to actually insert into the receipts table. The table is created by import_clean_receipts.create_receipts_table().

Column mapping assumptions (based on analyze_new_receipts_excel.py):
- id: ignored (left blank in source; DB will auto-number as receipt_id)
- receipt_date -> receipts.receipt_date (required)
- vendor_name -> receipts.vendor_name
- description -> receipts.description
- revenue, expense -> determine gross_amount:
    â€¢ If expense present (>0), gross_amount = expense (expense receipt)
    â€¢ Else if revenue present (>0), gross_amount = revenue (income receipt)
    â€¢ Else skip row
- gst_amount -> receipts.gst_amount (fallback from sales_tax if present)
- net_amount -> receipts.net_amount (fallback computed as gross - gst)
- payment method columns: prefer canonical_pay_method if present, else payment_method, else pay_method (stored in receipts.category hint or ignored)
- comment -> kept in description tail (appended) or ignored if empty
- vehicle_id, vehicle_number, fuel: carried through to preview for fuel pipeline; not inserted into receipts table directly
- Tracking columns like classification, sub_classification, tax_category, mapping_* etc are ignored for now.

You can adjust the mapping rules in code below if needed.
"""

import argparse
import os
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, List, Dict, Any

import pandas as pd

try:
    import psycopg2  # type: ignore
except Exception:
    psycopg2 = None  # Allows dry-run without DB libs installed

# Paths
XLSX_PATH = r"L:\limo\reports\new receipts fileoct.xlsx"
PREVIEW_CSV = r"L:\limo\reports\receipts_import_preview.csv"


def to_float(val) -> Optional[float]:
    if pd.isna(val) or val is None:
        return None
    try:
        s = str(val).strip().replace("$", "").replace(",", "")
        if s == "":
            return None
        return float(s)
    except Exception:
        return None


def parse_date(val) -> Optional[datetime]:
    if pd.isna(val) or val is None or str(val).strip() == "":
        return None
    try:
        return pd.to_datetime(val).date()
    except Exception:
        return None


def pick_payment_method(row: pd.Series) -> Optional[str]:
    for col in ["canonical_pay_method", "payment_method", "pay_method"]:
        if col in row and pd.notna(row[col]) and str(row[col]).strip() != "":
            return str(row[col]).strip()
    return None


def load_excel(path: str) -> pd.DataFrame:
    if not os.path.exists(path):
        raise FileNotFoundError(f"File not found: {path}")
    xl = pd.ExcelFile(path)
    # default to 'receipts' sheet if present, else first sheet
    sheet = 'receipts' if 'receipts' in xl.sheet_names else xl.sheet_names[0]
    df = xl.parse(sheet)
    df.columns = [str(c).strip() for c in df.columns]
    return df


def normalize_rows(df: pd.DataFrame) -> List[Dict[str, Any]]:
    used_cols = set(df.columns)
    out: List[Dict[str, Any]] = []
    skipped_no_date = 0
    skipped_no_amount = 0

    # Columns to drop (workflow/status only)
    drop_cols = {'Reviewed', 'Exported'}

    # Most common defaults (from sample and business rules)
    default_fill = {
        'currency': 'CAD',
        'document_type': 'G',
        'type': 'Receipt',
        'classification': 'Business',
        'sub_classification': 'Deductible',
        'tax_category': 'Deductible',
    }

    for _, row in df.iterrows():
        # Required: date
        receipt_date = parse_date(row.get('receipt_date'))
        if not receipt_date:
            skipped_no_date += 1
            continue

        expense = to_float(row.get('expense'))
        revenue = to_float(row.get('revenue'))
        gross_amount = expense if (expense is not None and expense > 0) else None
        if gross_amount is None and revenue is not None and revenue > 0:
            gross_amount = revenue

        if gross_amount is None or gross_amount == 0:
            skipped_no_amount += 1
            continue

        # Build row with all columns except workflow/status
        record = {}
        for col in df.columns:
            if col in drop_cols:
                continue
            val = row.get(col)
            # Clean up float conversion for known numeric columns
            if col.lower() in ['expense', 'revenue', 'gross_amount', 'gst_amount', 'sales_tax', 'net_amount', 'fuel']:
                val = to_float(val)
            elif col.lower() == 'receipt_date':
                val = receipt_date
            # Fill with default if missing and default exists
            if (val is None or (isinstance(val, str) and val.strip() == '')) and col in default_fill:
                val = default_fill[col]
            record[col] = val

        # Always include gross_amount for consistency
        record['gross_amount'] = gross_amount

        # Also fill any default columns not present in source
        for col, val in default_fill.items():
            if col not in record or record[col] is None or (isinstance(record[col], str) and record[col] == ''):
                record[col] = val

        out.append(record)

    return out


def preview(rows: List[Dict[str, Any]], out_csv: str) -> None:
    if not rows:
        print("No rows to preview")
        return
    df = pd.DataFrame(rows)
    df.to_csv(out_csv, index=False)
    total = len(df)
    expenses = (df['category'] != 'income').sum() if 'category' in df.columns else total
    incomes = (df['category'] == 'income').sum() if 'category' in df.columns else 0
    print(f"\nPreview written: {out_csv}")
    print(f"Rows: {total} | Expenses: {expenses} | Incomes: {incomes}")
    print("Sample:")
    print(df.head(5).to_string(index=False))


def insert_rows(rows: List[Dict[str, Any]]) -> None:
    if not rows:
        print("No rows to insert")
        return
    if psycopg2 is None:
        raise RuntimeError("psycopg2 not available; cannot commit to DB. Run without --commit or install psycopg2.")

    # DB config via env, consistent with import_clean_receipts
    DB_NAME = os.environ.get('DB_NAME', 'almsdata')
    DB_USER = os.environ.get('DB_USER', 'postgres')
    DB_PASSWORD = os.environ.get('DB_PASSWORD', os.environ.get("DB_PASSWORD"))
    DB_HOST = os.environ.get('DB_HOST', 'localhost')
    DB_PORT = int(os.environ.get('DB_PORT', '5432'))

    conn = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD, host=DB_HOST, port=DB_PORT)
    try:
        with conn.cursor() as cur:
            sql = (
                "INSERT INTO receipts (source_system, source_reference, source_hash, receipt_date, vendor_name, "
                "gross_amount, gst_amount, expense_account, description, category, revenue, expense, "
                "vehicle_id, vehicle_number, fuel)"
                " VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)"
            )
            
            import hashlib
            import uuid
            from datetime import datetime
            data = []
            for idx, r in enumerate(rows):
                # Generate source hash for deduplication (include row index for uniqueness)
                hash_input = f"{r['receipt_date']}{r.get('vendor_name', '')}{r['gross_amount']}{idx}"
                source_hash = hashlib.md5(hash_input.encode()).hexdigest()
                
                # Use expense_account from Excel or default
                expense_account = r.get('expense_account') or 'GENERAL_EXPENSE'
                
                # Create truly unique source_reference using UUID
                source_ref = f"excel_row_{idx}_{str(uuid.uuid4())[:8]}"
                
                # Convert vehicle_id to integer if present
                vehicle_id = r.get('vehicle_id')
                if pd.notna(vehicle_id):
                    vehicle_id = int(float(vehicle_id))
                else:
                    vehicle_id = None
                
                data.append((
                    'EXCEL',  # source_system
                    source_ref,  # source_reference (unique per row)
                    source_hash,  # source_hash
                    r['receipt_date'], 
                    r.get('vendor_name') or 'UNKNOWN VENDOR', 
                    r['gross_amount'], 
                    r.get('gst_amount') or 0.0,
                    expense_account,  # expense_account (required)
                    r.get('description'), 
                    r.get('category'), 
                    r.get('revenue'),
                    r.get('expense'), 
                    vehicle_id,  # converted to int or None
                    r.get('vehicle_number'), 
                    r.get('fuel')
                ))
            cur.executemany(sql, data)
        conn.commit()
        print(f"Inserted {len(rows)} rows into receipts")
    finally:
        conn.close()


def main():
    ap = argparse.ArgumentParser(description="Import receipts from Excel with dry-run preview")
    ap.add_argument('--file', default=XLSX_PATH, help='Path to Excel file')
    ap.add_argument('--commit', action='store_true', help='Insert into DB (default is dry-run)')
    ap.add_argument('--limit', type=int, default=None, help='Limit number of rows for test run')
    args = ap.parse_args()

    df = load_excel(args.file)
    rows = normalize_rows(df)
    if args.limit:
        rows = rows[: args.limit]

    # Always produce a preview CSV
    preview(rows, PREVIEW_CSV)

    if not args.commit:
        print("\nDry-run complete. Re-run with --commit to insert into receipts.")
        return

    insert_rows(rows)


if __name__ == '__main__':
    main()
